//  ================================================================
//  Created by Gregory Kramida on 11/1/19.
//  Copyright (c) 2019 Gregory Kramida
//  Licensed under the Apache License, Version 2.0 (the "License");
//  you may not use this file except in compliance with the License.
//  You may obtain a copy of the License at

//  http://www.apache.org/licenses/LICENSE-2.0

//  Unless required by applicable law or agreed to in writing, software
//  distributed under the License is distributed on an "AS IS" BASIS,
//  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
//  See the License for the specific language governing permissions and
//  limitations under the License.
//  ================================================================
#pragma once

//local
#include "IndexingEngine_CUDA_VoxelBlockHash.h"
#include "IndexingEngine_CUDA_VoxelBlockHash_Kernels.h"
#include "../../Interface/IndexingEngine.h"
#include "../../../../Utils/Configuration.h"
#include "../CPU/IndexingEngine_CPU_VoxelBlockHash.h"
#include "../../../../../ORUtils/PlatformIndependence.h"
#include "../../Shared/IndexingEngine_Functors.h"
#include "../../../Traversal/Interface/HashTableTraversal.h"

using namespace ITMLib;

namespace std {
template<>
struct hash<Vector3s> {
	size_t operator()(const Vector3s& vector) const {
		return std::hash<size_t>()(static_cast<size_t>(vector.x) << 16u | static_cast<size_t>(vector.y) << 8u |
		                           static_cast<size_t>(vector.z));
	}
};
} // namespace std

template<typename TVoxel>
template<typename TVoxelTarget, typename TVoxelSource, typename TMarkerFunctor>
void IndexingEngine<TVoxel, VoxelBlockHash, MEMORYDEVICE_CUDA>::AllocateUsingOtherVolume_Generic(
		VoxelVolume<TVoxelTarget, VoxelBlockHash>* target_volume,
		VoxelVolume<TVoxelSource, VoxelBlockHash>* source_volume,
		TMarkerFunctor& marker_functor) {

	assert(target_volume->index.hashEntryCount == source_volume->index.hashEntryCount);

	IndexingEngine<TVoxelTarget, VoxelBlockHash, MEMORYDEVICE_CUDA>& indexer =
			IndexingEngine<TVoxelTarget, VoxelBlockHash, MEMORYDEVICE_CUDA>::Instance();
	do {
		marker_functor.resetFlagsAndCounters();
		target_volume->index.ClearHashEntryAllocationStates();
		HashTableTraversalEngine<MEMORYDEVICE_CUDA>::TraverseUtilizedWithHashCode(
				source_volume->index, marker_functor);
		indexer.AllocateHashEntriesUsingAllocationStateList(target_volume);
		indexer.AllocateBlockList(target_volume, marker_functor.colliding_block_positions,
		                          marker_functor.getCollidingBlockCount());
	} while (marker_functor.encounteredUnresolvableCollision());

}

template<typename TVoxel>
template<typename TVoxelTarget, typename TVoxelSource>
void IndexingEngine<TVoxel, VoxelBlockHash, MEMORYDEVICE_CUDA>::AllocateUsingOtherVolume(
		VoxelVolume<TVoxelTarget, VoxelBlockHash>* target_volume,
		VoxelVolume<TVoxelSource, VoxelBlockHash>* source_volume) {
	VolumeBasedAllocationStateMarkerFunctor<MEMORYDEVICE_CUDA>
			volume_based_allocation_state_marker(target_volume->index);
	AllocateUsingOtherVolume_Generic(target_volume, source_volume, volume_based_allocation_state_marker);
}

template<typename TVoxel>
template<typename TVoxelTarget, typename TVoxelSource>
void IndexingEngine<TVoxel, VoxelBlockHash, MEMORYDEVICE_CUDA>::AllocateUsingOtherVolume_Bounded(
		VoxelVolume<TVoxelTarget, VoxelBlockHash>* target_volume,
		VoxelVolume<TVoxelSource, VoxelBlockHash>* source_volume,
		const Extent3D& bounds) {
	VolumeBasedBoundedAllocationStateMarkerFunctor<MEMORYDEVICE_CUDA> volume_based_allocation_state_marker(
			target_volume->index, bounds);
	AllocateUsingOtherVolume_Generic(target_volume, source_volume, volume_based_allocation_state_marker);
}

template<typename TVoxel>
template<typename TVoxelTarget, typename TVoxelSource>
void IndexingEngine<TVoxel, VoxelBlockHash, MEMORYDEVICE_CUDA>::AllocateUsingOtherVolume_OffsetAndBounded(
		VoxelVolume<TVoxelTarget, VoxelBlockHash>* target_volume,
		VoxelVolume<TVoxelSource, VoxelBlockHash>* source_volume,
		const Extent3D& source_bounds, const Vector3i& target_offset) {

	IndexingEngine<TVoxelTarget, VoxelBlockHash, MEMORYDEVICE_CUDA>& target_indexer =
			IndexingEngine<TVoxelTarget, VoxelBlockHash, MEMORYDEVICE_CUDA>::Instance();

	HashEntry* target_hash_table = target_volume->index.GetEntries();
	const HashEntry* source_hash_table = source_volume->index.GetEntries();

	Vector6i target_bounds(source_bounds.min_x + target_offset.x,
	                       source_bounds.min_y + target_offset.y,
	                       source_bounds.min_z + target_offset.z,
	                       source_bounds.max_x + target_offset.x,
	                       source_bounds.max_y + target_offset.y,
	                       source_bounds.max_z + target_offset.z);

	Vector3i min_target_block_coordinate(
			static_cast<int>(floor(static_cast<float>(target_bounds.min_x) / VOXEL_BLOCK_SIZE)),
			static_cast<int>(floor(static_cast<float>(target_bounds.min_y) / VOXEL_BLOCK_SIZE)),
			static_cast<int>(floor(static_cast<float>(target_bounds.min_z) / VOXEL_BLOCK_SIZE)));
	Vector3i max_target_block_coord(
			static_cast<int>(ceil(static_cast<float>(target_bounds.max_x) / VOXEL_BLOCK_SIZE)),
			static_cast<int>(ceil(static_cast<float>(target_bounds.max_y) / VOXEL_BLOCK_SIZE)),
			static_cast<int>(ceil(static_cast<float>(target_bounds.max_z) / VOXEL_BLOCK_SIZE)));
	Vector3i target_block_range(max_target_block_coord.x + 1 - min_target_block_coordinate.x,
	                            max_target_block_coord.y + 1 - min_target_block_coordinate.y,
	                            max_target_block_coord.z + 1 - min_target_block_coordinate.z);

	HashEntryAllocationState* hash_entry_allocation_states = target_volume->index.GetHashEntryAllocationStates();
	Vector3s* hash_block_coordinates = target_volume->index.GetAllocationBlockCoordinates();

	ORUtils::MemoryBlock<Vector3s> colliding_block_positions(target_volume->index.hashEntryCount, MEMORYDEVICE_CUDA);
	Vector3s* colliding_block_positions_device = colliding_block_positions.GetData(MEMORYDEVICE_CUDA);
	ORUtils::MemoryBlock<int> collidng_block_count(1, true, true);
	ORUtils::MemoryBlock<bool> unresolvable_collision_encountered(1, true, true);


	Vector6i inverse_offset_block_range;
	ComputeVoxelBlockOffsetRange(-target_offset, inverse_offset_block_range);
	dim3 cudaBlockSizeMK(8, 8, 8);
	dim3 gridSizeMK((int) ceil((float) target_block_range.x / (float) cudaBlockSizeMK.x),
	                (int) ceil((float) target_block_range.y / (float) cudaBlockSizeMK.x),
	                (int) ceil((float) target_block_range.z / (float) cudaBlockSizeMK.x));

	do {
		target_volume->index.ClearHashEntryAllocationStates();
		*collidng_block_count.GetData(MEMORYDEVICE_CPU) = 0;
		collidng_block_count.UpdateDeviceFromHost();
		*unresolvable_collision_encountered.GetData(MEMORYDEVICE_CPU) = false;
		unresolvable_collision_encountered.UpdateDeviceFromHost();

		determineTargetAllocationForOffsetCopy_device << < gridSizeMK, cudaBlockSizeMK >> > (
				target_hash_table, source_hash_table, hash_entry_allocation_states, hash_block_coordinates,
						target_bounds, inverse_offset_block_range, target_block_range, min_target_block_coordinate,
						colliding_block_positions_device, collidng_block_count.GetData(MEMORYDEVICE_CUDA),
						unresolvable_collision_encountered.GetData(MEMORYDEVICE_CUDA));
		ORcudaKernelCheck;
		collidng_block_count.UpdateHostFromDevice();
		target_indexer.AllocateHashEntriesUsingAllocationStateList(target_volume);
		target_indexer.AllocateBlockList(target_volume, colliding_block_positions,
		                                 *collidng_block_count.GetData(MEMORYDEVICE_CPU));
		unresolvable_collision_encountered.UpdateHostFromDevice();
	} while (*unresolvable_collision_encountered.GetData(MEMORYDEVICE_CPU));
}

template<typename TVoxel>
void IndexingEngine<TVoxel, VoxelBlockHash, MEMORYDEVICE_CUDA>::
AllocateHashEntriesUsingAllocationStateList(VoxelVolume<TVoxel, VoxelBlockHash>* volume) {

	const HashEntryAllocationState* hash_entry_allocation_states = volume->index.GetHashEntryAllocationStates();
	Vector3s* allocation_block_coordinates = volume->index.GetAllocationBlockCoordinates();

	const int hash_entry_count = volume->index.hashEntryCount;
	int* block_allocation_list = volume->localVBA.GetAllocationList();
	int* excess_allocation_list = volume->index.GetExcessAllocationList();
	int* utilized_block_hash_codes = volume->index.GetUtilizedBlockHashCodes();

	HashEntry* hashTable = volume->index.GetIndexData();

	ORUtils::MemoryBlock<AllocationTempData> allocationTempData(1, true, true);
	AllocationTempData* allocationTempData_host = allocationTempData.GetData(MEMORYDEVICE_CPU);
	allocationTempData_host->last_free_voxel_block_id = volume->localVBA.lastFreeBlockId;
	allocationTempData_host->last_free_excess_list_id = volume->index.GetLastFreeExcessListId();
	allocationTempData_host->utilized_block_count = volume->index.GetUtilizedHashBlockCount();
	allocationTempData.UpdateDeviceFromHost();

	dim3 cudaBlockSizeAL(256, 1);
	dim3 gridSizeAL((int) ceil((float) hash_entry_count / (float) cudaBlockSizeAL.x));

	allocateHashedVoxelBlocksUsingLists_device << < gridSizeAL, cudaBlockSizeAL >> > (
			block_allocation_list, excess_allocation_list, allocationTempData.GetData(MEMORYDEVICE_CUDA),
					hashTable, hash_entry_count, hash_entry_allocation_states, allocation_block_coordinates, utilized_block_hash_codes);
	ORcudaKernelCheck;
	allocationTempData.UpdateHostFromDevice();
	volume->localVBA.lastFreeBlockId = allocationTempData_host->last_free_voxel_block_id;
	volume->index.SetLastFreeExcessListId(allocationTempData_host->last_free_excess_list_id);
	volume->index.SetUtilizedHashBlockCount(allocationTempData_host->utilized_block_count);
}


template<typename TVoxel>
void IndexingEngine<TVoxel, VoxelBlockHash, MEMORYDEVICE_CUDA>::
AllocateHashEntriesUsingAllocationStateList_SetVisibility(VoxelVolume<TVoxel, VoxelBlockHash>* volume) {

	const HashEntryAllocationState* hash_entry_allocation_states_device = volume->index.GetHashEntryAllocationStates();
	Vector3s* allocationBlockCoordinates_device = volume->index.GetAllocationBlockCoordinates();
	HashBlockVisibility* hashBlockVisibilityTypes_device = volume->index.GetBlockVisibilityTypes();

	const int hashEntryCount = volume->index.hashEntryCount;

	int* voxelAllocationList = volume->localVBA.GetAllocationList();
	int* excessAllocationList = volume->index.GetExcessAllocationList();
	HashEntry* hashTable = volume->index.GetIndexData();

	ORUtils::MemoryBlock<AllocationTempData> allocationTempData(1, true, true);
	AllocationTempData* allocationTempData_host = allocationTempData.GetData(MEMORYDEVICE_CPU);
	allocationTempData_host->last_free_voxel_block_id = volume->localVBA.lastFreeBlockId;
	allocationTempData_host->last_free_excess_list_id = volume->index.GetLastFreeExcessListId();
	allocationTempData.UpdateDeviceFromHost();

	dim3 cudaBlockSizeAL(256, 1);
	dim3 gridSizeAL((int) ceil((float) hashEntryCount / (float) cudaBlockSizeAL.x));

	allocateHashedVoxelBlocksUsingLists_SetVisibility_device << < gridSizeAL, cudaBlockSizeAL >> > (
			voxelAllocationList, excessAllocationList, allocationTempData.GetData(MEMORYDEVICE_CUDA),
					hashTable, hashEntryCount, hash_entry_allocation_states_device,
					allocationBlockCoordinates_device, hashBlockVisibilityTypes_device);
	ORcudaKernelCheck;
	allocationTempData.UpdateHostFromDevice();
	volume->localVBA.lastFreeBlockId = allocationTempData_host->last_free_voxel_block_id;
	volume->index.SetLastFreeExcessListId(allocationTempData_host->last_free_excess_list_id);
}


template<typename TVoxel>
void IndexingEngine<TVoxel, VoxelBlockHash, MEMORYDEVICE_CUDA>::AllocateBlockList(
		VoxelVolume<TVoxel, VoxelBlockHash>* volume, const ORUtils::MemoryBlock<Vector3s>& new_block_positions,
		int new_block_count) {
	if (new_block_count == 0) return;

	ORUtils::MemoryBlock<Vector3s> new_positions_local(new_block_count, MEMORYDEVICE_CUDA);
	new_positions_local.SetFrom(&new_block_positions, MemoryCopyDirection::CUDA_TO_CUDA);
	ORUtils::MemoryBlock<Vector3s> colliding_positions_local(new_block_count, MEMORYDEVICE_CUDA);
	ORUtils::MemoryBlock<int> colliding_block_count(1, true, true);

	Vector3s* new_positions_device = new_positions_local.GetData(MEMORYDEVICE_CUDA);
	Vector3s* colliding_positions_device = colliding_positions_local.GetData(MEMORYDEVICE_CUDA);

	HashEntry* hash_table = volume->index.GetEntries();
	HashEntryAllocationState* hash_entry_states = volume->index.GetHashEntryAllocationStates();
	Vector3s* allocation_block_coordinates = volume->index.GetAllocationBlockCoordinates();

	while (new_block_count > 0) {
		*colliding_block_count.GetData(MEMORYDEVICE_CPU) = 0;
		colliding_block_count.UpdateDeviceFromHost();

		volume->index.ClearHashEntryAllocationStates();

		dim3 cuda_block_size(256);
		dim3 cuda_grid_size(
				static_cast<int>(ceil(static_cast<float>(new_block_count) / static_cast<float>(cuda_block_size.x))));

		buildHashAllocationTypeList_BlockList_device
				<< < cuda_grid_size, cuda_block_size >> >
		                             (new_positions_device, hash_entry_states,
				                             allocation_block_coordinates, hash_table, new_block_count,
				                             colliding_positions_device,
				                             colliding_block_count.GetData(MEMORYDEVICE_CUDA));

		ORcudaKernelCheck;

		AllocateHashEntriesUsingAllocationStateList(volume);

		colliding_block_count.UpdateHostFromDevice();
		new_block_count = *colliding_block_count.GetData(MEMORYDEVICE_CPU);
		std::swap(new_positions_device, colliding_positions_device);
	}
}


template<typename TVoxel>
void IndexingEngine<TVoxel, VoxelBlockHash, MEMORYDEVICE_CUDA>::BuildUtilizedBlockListBasedOnVisibility(
		VoxelVolume<TVoxel, VoxelBlockHash>* volume, const View* view,
		const Matrix4f& depth_camera_matrix) {

	// ** volume data **
	const int hash_entry_count = volume->index.hashEntryCount;
	HashBlockVisibility* hashBlockVisibilityTypes_device = volume->index.GetBlockVisibilityTypes();
	int* visibleBlockHashCodes_device = volume->index.GetUtilizedBlockHashCodes();
	HashEntry* hashTable = volume->index.GetEntries();
	bool useSwapping = volume->globalCache != nullptr;
	ITMHashSwapState* swapStates = volume->Swapping() ? volume->globalCache->GetSwapStates(false) : 0;

	// ** view data **
	Vector4f depthCameraProjectionParameters = view->calib.intrinsics_d.projectionParamsSimple.all;
	Vector2i depthImgSize = view->depth->noDims;
	float voxelSize = volume->sceneParams->voxel_size;


	// ** CUDA data **
	ORUtils::MemoryBlock<int> visibleBlockCount(1, true, true);
	dim3 cudaBlockSizeAL(256, 1);
	dim3 gridSizeAL((int) ceil((float) hash_entry_count / (float) cudaBlockSizeAL.x));

	if (useSwapping) {
		buildVisibilityList_device<true> << < gridSizeAL, cudaBlockSizeAL >> >
		                                                  (hashTable, swapStates, hash_entry_count, visibleBlockHashCodes_device,
				                                                  visibleBlockCount.GetData(
						                                                  MEMORYDEVICE_CUDA), hashBlockVisibilityTypes_device, depth_camera_matrix, depthCameraProjectionParameters, depthImgSize, voxelSize);
		ORcudaKernelCheck;
	} else {
		buildVisibilityList_device<false> << < gridSizeAL, cudaBlockSizeAL >> >
		                                                   (hashTable, swapStates, hash_entry_count, visibleBlockHashCodes_device,
				                                                   visibleBlockCount.GetData(
						                                                   MEMORYDEVICE_CUDA), hashBlockVisibilityTypes_device, depth_camera_matrix, depthCameraProjectionParameters, depthImgSize, voxelSize);
		ORcudaKernelCheck;
	}
	visibleBlockCount.UpdateHostFromDevice();
	volume->index.SetUtilizedHashBlockCount(*visibleBlockCount.GetData(MEMORYDEVICE_CPU));
}

template<typename TVoxel>
void
IndexingEngine<TVoxel, VoxelBlockHash, MEMORYDEVICE_CUDA>::SetVisibilityToVisibleAtPreviousFrameAndUnstreamed(
		VoxelVolume<TVoxel, VoxelBlockHash>* volume) {
	HashBlockVisibility* utilized_block_visibility_types = volume->index.GetBlockVisibilityTypes();
	const int* utilized_block_hash_codes = volume->index.GetUtilizedBlockHashCodes();
	const int utilized_block_count = volume->index.GetUtilizedHashBlockCount();
	dim3 cudaBlockSizeVS(256, 1);
	dim3 gridSizeVS((int) ceil((float) utilized_block_count / (float) cudaBlockSizeVS.x));
	if (gridSizeVS.x > 0) {
		setVisibleEntriesToVisibleAtPreviousFrameAndUnstreamed << < gridSizeVS, cudaBlockSizeVS >> >
		                                                                        (utilized_block_visibility_types,
				                                                                        utilized_block_hash_codes, utilized_block_count);
		ORcudaKernelCheck;
	}
}

template<typename TVoxel>
HashEntry
IndexingEngine<TVoxel, VoxelBlockHash, MEMORYDEVICE_CUDA>::FindHashEntry(const VoxelBlockHash& index,
                                                                         const Vector3s& coordinates) {
	const HashEntry* entries = index.GetEntries();
	ORUtils::MemoryBlock<int> hashCode(1, true, true);
	ORUtils::MemoryBlock<HashEntry> hashEntry(1, true, true);
	findHashEntry_device << < 1, 1 >> > (hashEntry.GetData(MEMORYDEVICE_CUDA), entries, coordinates, hashCode.GetData(
			MEMORYDEVICE_CUDA));
	hashEntry.UpdateHostFromDevice();
	hashCode.UpdateHostFromDevice();
	int hashCode_CPU = *hashCode.GetData(MEMORYDEVICE_CPU);
	if (hashCode_CPU == -1) {
		return {Vector3s(0, 0, 0), 0, -2};
	} else {
		HashEntry entry = *hashEntry.GetData(MEMORYDEVICE_CPU);
		return entry;
	}
}


template<typename TVoxel>
HashEntry
IndexingEngine<TVoxel, VoxelBlockHash, MEMORYDEVICE_CUDA>::FindHashEntry(const VoxelBlockHash& index,
                                                                         const Vector3s& coordinates,
                                                                         int& hashCode_CPU) {
	const HashEntry* entries = index.GetEntries();
	ORUtils::MemoryBlock<int> hashCode(1, true, true);
	ORUtils::MemoryBlock<HashEntry> hashEntry(1, true, true);
	findHashEntry_device << < 1, 1 >> > (hashEntry.GetData(MEMORYDEVICE_CUDA), entries, coordinates, hashCode.GetData(
			MEMORYDEVICE_CUDA));
	ORcudaKernelCheck;
	hashEntry.UpdateHostFromDevice();
	hashCode.UpdateHostFromDevice();
	hashCode_CPU = *hashCode.GetData(MEMORYDEVICE_CPU);
	if (hashCode_CPU == -1) {
		return {Vector3s(0, 0, 0), 0, -2};
	} else {
		HashEntry entry = *hashEntry.GetData(MEMORYDEVICE_CPU);
		return entry;
	}
}


template<typename TVoxel>
bool IndexingEngine<TVoxel, VoxelBlockHash, MEMORYDEVICE_CUDA>::AllocateHashBlockAt(
		VoxelVolume<TVoxel, VoxelBlockHash>* volume, Vector3s at, int& hash_code) {
	HashEntry* hash_table = volume->index.GetEntries();

	ORUtils::MemoryBlock<SingleHashAllocationData> data(1, true, true);

	SingleHashAllocationData* data_device = data.GetData(MEMORYDEVICE_CPU);
	data_device->lastFreeVoxelBlockId = volume->localVBA.lastFreeBlockId;
	data_device->lastFreeExcessListId = volume->index.GetLastFreeExcessListId();
	data_device->hashCode = -1;
	data_device->success = false;
	data.UpdateDeviceFromHost();

	int* voxel_allocation_list = volume->localVBA.GetAllocationList();
	int* excess_allocation_list = volume->index.GetExcessAllocationList();

	allocateHashEntry_device << < 1, 1 >> >
	                                 (data.GetData(
			                                 MEMORYDEVICE_CUDA), at, hash_table, voxel_allocation_list, excess_allocation_list);

	ORcudaKernelCheck;
	data.UpdateHostFromDevice();

	if (!data_device->success) {
		return false;
	}

	hash_code = data_device->hashCode;

	volume->localVBA.lastFreeBlockId = data_device->lastFreeVoxelBlockId;
	volume->index.SetLastFreeExcessListId(data_device->lastFreeExcessListId);
	return true;
}



