//  ================================================================
//  Created by Gregory Kramida on 7/24/18.
//  Copyright (c) 2018-2025 Gregory Kramida
//  Licensed under the Apache License, Version 2.0 (the "License");
//  you may not use this file except in compliance with the License.
//  You may obtain a copy of the License at

//  http://www.apache.org/licenses/LICENSE-2.0

//  Unless required by applicable law or agreed to in writing, software
//  distributed under the License is distributed on an "AS IS" BASIS,
//  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
//  See the License for the specific language governing permissions and
//  limitations under the License.
//  ================================================================

#include "ITMSceneManipulationEngine_CUDA.h"
#include "../Shared/ITMSceneManipulationEngine_Shared.h"
#include "../../../Utils/ITMCUDAUtils.h"
#include "../../../../ORUtils/PlatformIndependence.h"
#include "../../../../ORUtils/JetbrainsCUDASyntax.hpp"
#include "../../../Objects/Scene/ITMRepresentationAccess.h"
#include "../../../Utils/ITMGeometryOpernations.h"
#include "../../../Utils/Analytics/SceneStatisticsCalculator/CUDA/ITMSceneStatisticsCalculator_CUDA.h"
#include "ITMSceneManipulationEngine_CUDA_VoxelBlockHash_Kernels.h"

#include <cstring>
#include <limits>


// region ================================== VOXEL BLOCK HASH ==========================================================


template<typename TVoxel>
ITMSceneManipulationEngine_CUDA<TVoxel, ITMVoxelBlockHash>::ITMSceneManipulationEngine_CUDA() {
	ORcudaSafeCall(cudaMalloc((void**) &allocationTempData_device, sizeof(CopyAllocationTempData)));
	ORcudaSafeCall(cudaMallocHost((void**) &allocationTempData_host, sizeof(CopyAllocationTempData)));

	ORcudaSafeCall(cudaMalloc((void**) &readVoxelResult_device, sizeof(ReadVoxelResult<TVoxel>)));
	ORcudaSafeCall(cudaMallocHost((void**) &readVoxelResult_host, sizeof(ReadVoxelResult<TVoxel>)));

	int noTotalEntries = ITMVoxelBlockHash::noTotalEntries;
	ORcudaSafeCall(cudaMalloc((void**) &entriesAllocType_device, noTotalEntries));
	ORcudaSafeCall(cudaMalloc((void**) &blockCoords_device, noTotalEntries * sizeof(Vector3s)));
}

template<typename TVoxel>
ITMSceneManipulationEngine_CUDA<TVoxel, ITMVoxelBlockHash>::~ITMSceneManipulationEngine_CUDA() {
	ORcudaSafeCall(cudaFree(allocationTempData_device));
	ORcudaSafeCall(cudaFreeHost(allocationTempData_host));
	ORcudaSafeCall(cudaFree(readVoxelResult_device));
	ORcudaSafeCall(cudaFreeHost(readVoxelResult_host));
	ORcudaSafeCall(cudaFree(entriesAllocType_device));
	ORcudaSafeCall(cudaFree(blockCoords_device));
}


template<typename TVoxel>
void
ITMSceneManipulationEngine_CUDA<TVoxel, ITMVoxelBlockHash>::ResetScene(
		ITMVoxelVolume<TVoxel, ITMVoxelBlockHash>* scene) {
	int numBlocks = scene->index.getNumAllocatedVoxelBlocks();
	int blockSize = scene->index.getVoxelBlockSize();

	TVoxel* voxelBlocks_ptr = scene->localVBA.GetVoxelBlocks();
	memsetKernel<TVoxel>(voxelBlocks_ptr, TVoxel(), numBlocks * blockSize);
	int* vbaAllocationList_ptr = scene->localVBA.GetAllocationList();
	fillArrayKernel<int>(vbaAllocationList_ptr, numBlocks);
	scene->localVBA.lastFreeBlockId = numBlocks - 1;

	ITMHashEntry tmpEntry;
	memset(&tmpEntry, 0, sizeof(ITMHashEntry));
	tmpEntry.ptr = -2;
	ITMHashEntry* hashEntry_ptr = scene->index.GetEntries();
	memsetKernel<ITMHashEntry>(hashEntry_ptr, tmpEntry, scene->index.noTotalEntries);
	int* excessList_ptr = scene->index.GetExcessAllocationList();
	fillArrayKernel<int>(excessList_ptr, SDF_EXCESS_LIST_SIZE);

	scene->index.SetLastFreeExcessListId(SDF_EXCESS_LIST_SIZE - 1);
}

template<typename TVoxel>
bool
ITMSceneManipulationEngine_CUDA<TVoxel, ITMVoxelBlockHash>::SetVoxel(ITMVoxelVolume<TVoxel, ITMVoxelBlockHash>* scene,
                                                                     Vector3i at, TVoxel voxel) {
	ITMHashEntry* hashTable = scene->index.GetEntries();

	TVoxel* voxels = scene->localVBA.GetVoxelBlocks();
	int* voxelAllocationList = scene->localVBA.GetAllocationList();
	int* excessAllocationList = scene->index.GetExcessAllocationList();

	CopyAllocationTempData* tempData_host = (CopyAllocationTempData*) allocationTempData_host;
	tempData_host->noAllocatedVoxelEntries = scene->localVBA.lastFreeBlockId;
	tempData_host->noAllocatedExcessEntries = scene->index.GetLastFreeExcessListId();
	tempData_host->noBlocksToCopy = 0;
	tempData_host->success = false;

	ORcudaSafeCall(cudaMemcpyAsync(allocationTempData_device, tempData_host, sizeof(CopyAllocationTempData),
	                               cudaMemcpyHostToDevice));
	Vector3s blockPos;
	int voxelIndexInBlock = pointToVoxelBlockPos(at, blockPos);

	setVoxel_device<TVoxel> << < 1, 1 >> >
	                                (voxels, hashTable, at, voxel, (CopyAllocationTempData*) allocationTempData_device,
			                                voxelAllocationList, excessAllocationList, voxelIndexInBlock, blockPos);
	ORcudaKernelCheck;
	ORcudaSafeCall(
			cudaMemcpy(tempData_host, allocationTempData_device, sizeof(CopyAllocationTempData), cudaMemcpyDeviceToHost));

	scene->localVBA.lastFreeBlockId = tempData_host->noAllocatedVoxelEntries;
	scene->index.SetLastFreeExcessListId(tempData_host->noAllocatedExcessEntries);
	return tempData_host->success;
}


template<typename TVoxel>
TVoxel
ITMSceneManipulationEngine_CUDA<TVoxel, ITMVoxelBlockHash>::ReadVoxel(ITMVoxelVolume<TVoxel, ITMVoxelBlockHash>* scene,
                                                                      Vector3i at) {
	TVoxel* localVBA = scene->localVBA.GetVoxelBlocks();
	const ITMHashEntry* hashTable = scene->index.GetEntries();

	readVoxel_device<TVoxel> << < 1, 1 >> >
	                                 (localVBA, hashTable, at, (ReadVoxelResult<TVoxel>*) readVoxelResult_device);
	ORcudaKernelCheck;

	ReadVoxelResult<TVoxel>* readVoxelResult = (ReadVoxelResult<TVoxel>*) readVoxelResult_host;
	ORcudaSafeCall(cudaMemcpy(readVoxelResult_host, readVoxelResult_device, sizeof(ReadVoxelResult<TVoxel>),
	                          cudaMemcpyDeviceToHost));

	if (readVoxelResult->found) {
		return readVoxelResult->voxel;
	} else {
		TVoxel voxel;
		return voxel;
	}
}

template<typename TVoxel>
TVoxel
ITMSceneManipulationEngine_CUDA<TVoxel, ITMVoxelBlockHash>::ReadVoxel(ITMVoxelVolume<TVoxel, ITMVoxelBlockHash>* scene,
                                                                      Vector3i at,
                                                                      ITMVoxelBlockHash::IndexCache& cache) {
	TVoxel* localVBA = scene->localVBA.GetVoxelBlocks();
	const ITMHashEntry* hashTable = scene->index.GetEntries();

	readVoxel_device<TVoxel> << < 1, 1 >> >
	                                 (localVBA, hashTable, at, (ReadVoxelResult<TVoxel>*) readVoxelResult_device, &cache);
	ReadVoxelResult<TVoxel>* readVoxelResult = (ReadVoxelResult<TVoxel>*) readVoxelResult_host;
	ORcudaSafeCall(cudaMemcpy(readVoxelResult_host, readVoxelResult_device, sizeof(ReadVoxelResult<TVoxel>),
	                          cudaMemcpyDeviceToHost));

	if (readVoxelResult->found) {
		return readVoxelResult->voxel;
	} else {
		TVoxel voxel;
		return voxel;
	}
}

template<typename TVoxel>
void ITMSceneManipulationEngine_CUDA<TVoxel, ITMVoxelBlockHash>::OffsetWarps(
		ITMVoxelVolume<TVoxel, ITMVoxelBlockHash>* scene,
		Vector3f offset) {
	DIEWITHEXCEPTION_REPORTLOCATION("Not implemented");
}

template<typename TVoxel>
bool ITMSceneManipulationEngine_CUDA<TVoxel, ITMVoxelBlockHash>::CopySceneSlice(
		ITMVoxelVolume<TVoxel, ITMVoxelBlockHash>* destination, ITMVoxelVolume<TVoxel, ITMVoxelBlockHash>* source,
		Vector6i bounds, const Vector3i& offset) {

	int totalHashEntryCount = source->index.noTotalEntries;


	TVoxel* sourceVoxels = source->localVBA.GetVoxelBlocks();
	const ITMHashEntry* sourceHashTable = source->index.GetEntries();

	ITMHashEntry* destinationHashTable = destination->index.GetEntries();
	TVoxel* destinationVoxels = destination->localVBA.GetVoxelBlocks();
	int* voxelAllocationList = destination->localVBA.GetAllocationList();
	int* excessAllocationList = destination->index.GetExcessAllocationList();

	CopyAllocationTempData* tempData = (CopyAllocationTempData*) allocationTempData_host;
	tempData->noAllocatedVoxelEntries = destination->localVBA.lastFreeBlockId;
	tempData->noAllocatedExcessEntries = destination->index.GetLastFreeExcessListId();
	tempData->noBlocksToCopy = 0;
	tempData->success = false;
	ORcudaSafeCall(
			cudaMemcpyAsync(allocationTempData_device, tempData, sizeof(CopyAllocationTempData), cudaMemcpyHostToDevice));

	ORcudaSafeCall(cudaMemsetAsync(entriesAllocType_device, 0, sizeof(unsigned char) * totalHashEntryCount));
	Vector6i destinationBounds(bounds.min_x + offset.x, bounds.min_y + offset.y, bounds.min_z + offset.z,
	                           bounds.max_x + offset.x, bounds.max_y + offset.y, bounds.max_z + offset.z);

	if (offset == Vector3i(0)) {
		ORUtils::MemoryBlock<CopyHashBlockPairInfo> copyHashIdBlock(totalHashEntryCount, MEMORYDEVICE_CUDA);
		CopyHashBlockPairInfo* copyHashIdBuffer = copyHashIdBlock.GetData(MEMORYDEVICE_CUDA);

		// no offset; direct copy
		dim3 cudaBlockSizeAL(256, 1);
		dim3 gridSizeAL((int) ceil((float) totalHashEntryCount / (float) cudaBlockSizeAL.x));
		determineDestinationAllocationForNoOffsetCopy_device << < gridSizeAL, cudaBlockSizeAL >> > (
				destinationHashTable, sourceHashTable, totalHashEntryCount, entriesAllocType_device,
						blockCoords_device, (CopyAllocationTempData*) allocationTempData_device, copyHashIdBuffer, bounds);
		ORcudaKernelCheck;
		ORcudaSafeCall(
				cudaMemcpy(tempData, allocationTempData_device, sizeof(CopyAllocationTempData), cudaMemcpyDeviceToHost));
		if (tempData->noBlocksToCopy == 0) return false; //source volume empty in bounds or destination hash full
		allocateVoxelBlocksList_device << < gridSizeAL, cudaBlockSizeAL >> > (voxelAllocationList, excessAllocationList,
				(CopyAllocationTempData*) allocationTempData_device, destinationHashTable, totalHashEntryCount,
				entriesAllocType_device, blockCoords_device);
		ORcudaKernelCheck;


		destination->localVBA.lastFreeBlockId = tempData->noAllocatedVoxelEntries;
		destination->index.SetLastFreeExcessListId(tempData->noAllocatedExcessEntries);

		dim3 cudaBlockSizeCP(SDF_BLOCK_SIZE, SDF_BLOCK_SIZE, SDF_BLOCK_SIZE);
		dim3 gridSizeCP(tempData->noBlocksToCopy);

		noOffsetCopy_device<TVoxel> << < gridSizeCP, cudaBlockSizeCP >> > (destinationVoxels, sourceVoxels,
				destinationHashTable, sourceHashTable, tempData->noBlocksToCopy, copyHashIdBuffer, bounds);
		ORcudaKernelCheck;
	} else {
		ORUtils::MemoryBlock<OffsetCopyHashBlockInfo> copyHashIdBlock(totalHashEntryCount, MEMORYDEVICE_CUDA);
		OffsetCopyHashBlockInfo* copyHashIdBuffer = copyHashIdBlock.GetData(MEMORYDEVICE_CUDA);
		Vector3i minDestinationBlockCoord(
				static_cast<int>(floor(static_cast<float>(destinationBounds.min_x) / SDF_BLOCK_SIZE)),
				static_cast<int>(floor(static_cast<float>(destinationBounds.min_y) / SDF_BLOCK_SIZE)),
				static_cast<int>(floor(static_cast<float>(destinationBounds.min_z) / SDF_BLOCK_SIZE)));
		Vector3i maxDestinationBlockCoord(
				static_cast<int>(ceil(static_cast<float>(destinationBounds.max_x) / SDF_BLOCK_SIZE)),
				static_cast<int>(ceil(static_cast<float>(destinationBounds.max_y) / SDF_BLOCK_SIZE)),
				static_cast<int>(ceil(static_cast<float>(destinationBounds.max_z) / SDF_BLOCK_SIZE)));
		Vector3i destinationBlockRange(maxDestinationBlockCoord.x + 1 - minDestinationBlockCoord.x,
		                               maxDestinationBlockCoord.y + 1 - minDestinationBlockCoord.y,
		                               maxDestinationBlockCoord.z + 1 - minDestinationBlockCoord.z);

		Vector6i inverseOffsetBlockRange;
		ComputeVoxelBlockOffsetRange(-offset, inverseOffsetBlockRange);
		dim3 cudaBlockSizeMK(8, 8, 8);
		dim3 gridSizeMK((int) ceil((float) destinationBlockRange.x / (float) cudaBlockSizeMK.x),
		                (int) ceil((float) destinationBlockRange.y / (float) cudaBlockSizeMK.x),
		                (int) ceil((float) destinationBlockRange.z / (float) cudaBlockSizeMK.x));

		determineDestinationAllocationForOffsetCopy_device << < gridSizeMK, cudaBlockSizeMK >> > (
				destinationHashTable, sourceHashTable, entriesAllocType_device,
						blockCoords_device, (CopyAllocationTempData*) allocationTempData_device, copyHashIdBuffer,
						destinationBounds, inverseOffsetBlockRange, destinationBlockRange, minDestinationBlockCoord);
		ORcudaKernelCheck;
		ORcudaSafeCall(
				cudaMemcpy(tempData, allocationTempData_device, sizeof(CopyAllocationTempData), cudaMemcpyDeviceToHost));
		if (tempData->noBlocksToCopy == 0) return false; //source volume empty in bounds or destination hash full

		dim3 cudaBlockSizeAL(256, 1);
		dim3 gridSizeAL((int) ceil((float) totalHashEntryCount / (float) cudaBlockSizeAL.x));

		allocateVoxelBlocksList_device << < gridSizeAL, cudaBlockSizeAL >> > (voxelAllocationList, excessAllocationList,
				(CopyAllocationTempData*) allocationTempData_device, destinationHashTable, totalHashEntryCount,
				entriesAllocType_device, blockCoords_device);
		ORcudaKernelCheck;

		destination->localVBA.lastFreeBlockId = tempData->noAllocatedVoxelEntries;
		destination->index.SetLastFreeExcessListId(tempData->noAllocatedExcessEntries);

		dim3 cudaBlockSizeCP(SDF_BLOCK_SIZE, SDF_BLOCK_SIZE, SDF_BLOCK_SIZE);
		dim3 gridSizeCP(tempData->noBlocksToCopy);

		offsetCopy_device<TVoxel> << < gridSizeCP, cudaBlockSizeCP >> > (destinationVoxels, sourceVoxels,
				destinationHashTable, sourceHashTable, tempData->noBlocksToCopy, copyHashIdBuffer, offset, bounds);
		ORcudaKernelCheck;
	}

	return tempData->success;
}

template<typename TVoxel>
bool ITMSceneManipulationEngine_CUDA<TVoxel, ITMVoxelBlockHash>::CopyScene(
		ITMVoxelVolume<TVoxel, ITMVoxelBlockHash>* destination,
		ITMVoxelVolume<TVoxel, ITMVoxelBlockHash>* source,
		const Vector3i& offset) {

	int totalHashEntryCount = source->index.noTotalEntries;


	TVoxel* sourceVoxels = source->localVBA.GetVoxelBlocks();
	const ITMHashEntry* sourceHashTable = source->index.GetEntries();

	ITMHashEntry* destinationHashTable = destination->index.GetEntries();
	TVoxel* destinationVoxels = destination->localVBA.GetVoxelBlocks();
	int* voxelAllocationList = destination->localVBA.GetAllocationList();
	int* excessAllocationList = destination->index.GetExcessAllocationList();

	CopyAllocationTempData* tempData = (CopyAllocationTempData*) allocationTempData_host;
	tempData->noAllocatedVoxelEntries = destination->localVBA.lastFreeBlockId;
	tempData->noAllocatedExcessEntries = destination->index.GetLastFreeExcessListId();
	tempData->noBlocksToCopy = 0;
	tempData->success = false;
	ORcudaSafeCall(
			cudaMemcpyAsync(allocationTempData_device, tempData, sizeof(CopyAllocationTempData), cudaMemcpyHostToDevice));

	ORcudaSafeCall(cudaMemsetAsync(entriesAllocType_device, 0, sizeof(unsigned char) * totalHashEntryCount));

	if (offset == Vector3i(0)) {
		ORUtils::MemoryBlock<CopyHashBlockPairInfo> copyHashIdBlock(totalHashEntryCount, MEMORYDEVICE_CUDA);
		CopyHashBlockPairInfo* copyHashIdBuffer = copyHashIdBlock.GetData(MEMORYDEVICE_CUDA);

		// no offset; direct copy
		dim3 cudaBlockSizeAL(256, 1);
		dim3 gridSizeAL((int) ceil((float) totalHashEntryCount / (float) cudaBlockSizeAL.x));
		// compile lists of blocks to be allocated and lists of block pairs to be copied
		determineDestinationAllocationForNoOffsetCopy_device << < gridSizeAL, cudaBlockSizeAL >> > (
				destinationHashTable, sourceHashTable, totalHashEntryCount, entriesAllocType_device,
						blockCoords_device, (CopyAllocationTempData*) allocationTempData_device, copyHashIdBuffer);
		ORcudaKernelCheck;
		// allocate the necessary voxel blocks in the destination structure.
		allocateVoxelBlocksList_device << < gridSizeAL, cudaBlockSizeAL >> > (voxelAllocationList, excessAllocationList,
				(CopyAllocationTempData*) allocationTempData_device, destinationHashTable, totalHashEntryCount,
				entriesAllocType_device, blockCoords_device);
		ORcudaKernelCheck;

		ORcudaSafeCall(
				cudaMemcpy(tempData, allocationTempData_device, sizeof(CopyAllocationTempData), cudaMemcpyDeviceToHost));
		destination->localVBA.lastFreeBlockId = tempData->noAllocatedVoxelEntries;
		destination->index.SetLastFreeExcessListId(tempData->noAllocatedExcessEntries);

		dim3 cudaBlockSizeCP(SDF_BLOCK_SIZE, SDF_BLOCK_SIZE, SDF_BLOCK_SIZE);
		dim3 gridSizeCP(tempData->noBlocksToCopy);

		// dummy bounds, to avoid writing yet another function for copying -- blocks are expected to all be marked
		// "fullyInBounds", so we should be good
		Vector6i bounds;
		noOffsetCopy_device<TVoxel> << < gridSizeCP, cudaBlockSizeCP >> > (destinationVoxels, sourceVoxels,
				destinationHashTable, sourceHashTable, tempData->noBlocksToCopy, copyHashIdBuffer, bounds);
		ORcudaKernelCheck;
	} else {
		Vector6i bounds = ITMSceneStatisticsCalculator_CUDA<TVoxel, ITMVoxelBlockHash>::Instance().ComputeVoxelBounds(
				source);
		tempData->success = CopySceneSlice(destination, source, bounds, offset);
	}

	return tempData->success;

}

// endregion ===========================================================================================================
